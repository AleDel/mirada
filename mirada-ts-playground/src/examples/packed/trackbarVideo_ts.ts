
export const trackbarVideo_ts: string = "import * as Mirada from 'mirada'\ndeclare var cv: Mirada.CV\n\n(async () => {\n\n  var url1 = 'https://cancerberosgx.github.io/demos/media/video1.mp4';\n  var url2 = 'https://cancerberosgx.github.io/demos/media/video2.mp4';\nlet   processing = false;\n  const FPS = 30;\n  installControls();\n\n  // const canvas1 = document.getElementById('customCanvas1')! as HTMLCanvasElement;\n  // const canvas2 = document.getElementById('customCanvas2')! as HTMLCanvasElement;\n  const outputCanvas = document.getElementById('outputCanvas')! as HTMLCanvasElement;\n  const video1 = document.getElementById('customVideo1')! as HTMLVideoElement;\n  const video2 = document.getElementById('customVideo2')! as HTMLVideoElement;\n  let trackbar = document.getElementById('trackbar')! as HTMLInputElement\n\n  //  main();\n// \n//  let src1:cv.Mat = null as any\n//  let src2:cv.Mat\n//  let dst:cv.Mat\n// let cap1: cv.VideoCapture\n// let cap2: cv.VideoCapture\n\n    const  src1 = new cv.Mat(video1.height, video1.width, cv.CV_8UC4);\n   const   src2 = new cv.Mat(video2.height, video2.width, cv.CV_8UC4);\n const    dst = new cv.Mat(video1.height, video1.width, cv.CV_8UC1);\n const   cap1 = new cv.VideoCapture(video1);\n const   cap2 = new cv.VideoCapture(video2);\n\n\n\n    video1.src = url1\n    video2.src = url2\n  processing = true\n  // await video1.play()\nawait Promise.all([video1.play(), video1.play()]);\n  // start1(); start2()\n  setTimeout(()=>{\nuninstallControls()\n// cap1.\n  }, 15000)\n\n// async function main() {\n\n// }\n\n\n  const processVideo = () => {\n      try {\n        if (!processing) {\n          src1.delete();\n          src2.delete();\n          dst.delete()\n          return;\n        }\n        else {\n          const begin = Date.now();\n          \ncap1.read(src1)\n          cap2.read(src2);\n//            var orange = await Mirada.fromUrl('orange.png')\n//   // var apple = await Mirada.fromUrl('apple.png')\n//   // let dst = new cv.Mat()\n//   // const listener = () => {\n    let alpha = trackbar.valueAsNumber / parseInt(trackbar.max)\n    let beta = 1.0 - alpha\n    cv.addWeighted(src1, alpha, src2, beta, 0.0, dst, -1)\n    cv.imshow(outputCanvas, dst)\n\n          // cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);\n          // cv.imshow(outputCanvas, dst);\n          const delay = 1000 / FPS - (Date.now() - begin);\n          setTimeout(processVideo, delay);\n        }\n      }\n      catch (err) {\n        console.error(err);\n      }\n    };\n\n\nfunction  uninstallControls() {\n  processing=false\nif(document.querySelector('#outputContainer>.customWrapper')) {\n  document.querySelector('#outputContainer>.customWrapper')!.remove()\n  // alert('please reload the page')\n  // return\n}\n}\nfunction installControls() {\nuninstallControls()\n  const el = document.querySelector('#outputContainer>.wrapper')!\n  el.insertAdjacentHTML('afterend', `\n  <div class=\"customWrapper\">\n  <h5>Below are two input videos - use this slider to  morph between them</h5>\n    <input type=\"range\" id=\"trackbar\" value=\"50\" min=\"0\" max=\"100\" step=\"1\"/>\n\n<label  >input 1<br/><video crossOrigin=\"anonymous\" id=\"customVideo1\" width=\"320\" height=\"240\" muted /></label>\n    <label  >input 1<br/><video crossOrigin=\"anonymous\" id=\"customVideo2\" width=\"320\" height=\"240\" muted /></label>\n    </div>\n `);\n}\n})()\n\n  // const video = document.getElementById('videoInput')! as HTMLVideoElement\n// const  [processVideo, processVideo2]  = \n// Promise.all([video1.play(), video2.play()]).then(()=>{\n  // processing = true\n// })\n    // video1.src = url1\n    // video2.src = url2\n\n// debugger\n// const  [processVideo1, processVideo2] = [ await setupVideo(video1, canvas1, url1) , await setupVideo(video2, canvas2, url2)  ]\n// .then(()=>{\n//   processing = true\n// })\n\n// const  [start1, start2] = await Promise.all([setupVideo(video1, canvas1, url1),await setupVideo(video2, canvas2, url2) ])\n\n\n\n//  async  function setupVideo(video: HTMLVideoElement, canvas: HTMLCanvasElement, url: string) {\n//    debugger\n    \n//     return  processVideo\n//   }\n\n\n  // // const canvas = document.getElementById('outputCanvas')!\n  // // canvas.insertAdjacentHTML('afterend', `<input type=\"range\" id=\"trackbar\" value=\"50\" min=\"0\" max=\"100\" step=\"1\">`)\n  // var orange = await Mirada.fromUrl('orange.png')\n  // var apple = await Mirada.fromUrl('apple.png')\n  // let dst = new cv.Mat()\n  // let trackbar = document.getElementById('trackbar')! as HTMLInputElement\n  // const listener = () => {\n  //   let alpha = trackbar.valueAsNumber / parseInt(trackbar.max)\n  //   let beta = (1.0 - alpha)\n  //   cv.addWeighted(orange, alpha, apple, beta, 0.0, dst, -1)\n  //   cv.imshow(canvas, dst)\n  // }\n  // trackbar.addEventListener('input', listener)\n\n  // await sleep(600)\n  // listener()\n  // await sleep(12000)\n  // trackbar.removeEventListener('input', listener)\n  // document.getElementById('trackbar')!.remove()\n  // async function sleep(ms = 1000) { await new Promise(resolve => setTimeout(resolve, 1000)) }\n\n\n\n\n// }\n  // let cap1 = new cv.VideoCapture(video1)\n  // // take first frame of the video\n  // let frame1 = new cv.Mat(video1.height, video1.width, cv.CV_8UC4)\n  // cap1.read(frame1)\n  // let cap2 = new cv.VideoCapture(video2)\n  // let frame2 = new cv.Mat(video2.height, video2.width, cv.CV_8UC4)\n  // cap2.read(frame2)\n\n// function f (){} \n\n//   let video = document.getElementById('videoInput')! as HTMLVideoElement\n//   const canvas = document.getElementById('outputCanvas')! as HTMLCanvasElement\n//   let cap = new cv.VideoCapture(video)\n//   // take first frame of the video\n//   let frame1 = new cv.Mat(video.height, video.width, cv.CV_8UC4)\n//   cap.read(frame1)\n\n//   let prvs = new cv.Mat()\n//   cv.cvtColor(frame1, prvs, cv.COLOR_RGBA2GRAY)\n//   frame1.delete()\n//   let hsv = new cv.Mat()\n//   let hsv0 = new cv.Mat(video.height, video.width, cv.CV_8UC1)\n//   let hsv1 = new cv.Mat(video.height, video.width, cv.CV_8UC1, new cv.Scalar(255))\n//   let hsv2 = new cv.Mat(video.height, video.width, cv.CV_8UC1)\n//   let hsvVec = new cv.MatVector()\n//   hsvVec.push_back(hsv0); hsvVec.push_back(hsv1); hsvVec.push_back(hsv2)\n\n//   let frame2 = new cv.Mat(video.height, video.width, cv.CV_8UC4)\n//   let next = new cv.Mat(video.height, video.width, cv.CV_8UC1)\n//   let flow = new cv.Mat(video.height, video.width, cv.CV_32FC2)\n//   let flowVec = new cv.MatVector()\n//   let mag = new cv.Mat(video.height, video.width, cv.CV_32FC1)\n//   let ang = new cv.Mat(video.height, video.width, cv.CV_32FC1)\n//   let rgb = new cv.Mat(video.height, video.width, cv.CV_8UC3)\n\n//   const FPS = 30\n//   const videoHelper = new Mirada.CameraHelper(video, canvas, processVideo)\n//   function processVideo() {\n//     try {\n//       if (!videoHelper.streaming) {\n//         // clean and stop.\n//         prvs.delete(); hsv.delete(); hsv0.delete(); hsv1.delete(); hsv2.delete()\n//         hsvVec.delete(); frame2.delete(); flow.delete(); flowVec.delete(); next.delete()\n//         mag.delete(); ang.delete(); rgb.delete()\n//         return\n//       }\n//       let begin = Date.now()\n//       // processVideo processing.\n//       cap.read(frame2)\n//       cv.cvtColor(frame2, next, cv.COLOR_RGBA2GRAY)\n//       cv.calcOpticalFlowFarneback(prvs, next, flow, 0.5, 3, 15, 3, 5, 1.2, 0)\n//       cv.split(flow, flowVec)\n//       let u = flowVec.get(0)\n//       let v = flowVec.get(1)\n//       cv.cartToPolar(u, v, mag, ang)\n//       u.delete(); v.delete()\n//       ang.convertTo(hsv0, cv.CV_8UC1, 180 / Math.PI / 2)\n//       cv.normalize(mag, hsv2, 0, 255, cv.NORM_MINMAX, cv.CV_8UC1)\n//       cv.merge(hsvVec, hsv)\n//       cv.cvtColor(hsv, rgb, cv.COLOR_HSV2RGB)\n//       cv.imshow('outputCanvas', rgb)\n//       next.copyTo(prvs)\n//       // schedule the next one.\n//       let delay = 1000 / FPS - (Date.now() - begin)\n//       setTimeout(processVideo, delay)\n//     } catch (err) {\n//       console.error(err)\n//     }\n//   }\n//   setTimeout(() => videoHelper.processVideo(), 0)\n//   setTimeout(() => videoHelper.stop(), 10000)\n\n";
