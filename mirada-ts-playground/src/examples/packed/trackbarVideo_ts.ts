
export const trackbarVideo_ts: string = "import * as Mirada from 'mirada'\nimport { start } from 'repl';\ndeclare var cv: Mirada.CV\n\n(async () => {\n  var url1 = 'https://cancerberosgx.github.io/demos/media/video1.mp4'\n  var url2 = 'https://cancerberosgx.github.io/demos/media/video2.mp4'\n\n  const el = document.querySelector('#outputContainer>.wrapper')!\n  el.classList.add('hidden')\n\n  el.insertAdjacentHTML('beforebegin', `\n<table id=\"customWrapper\">\n  <tr>\n    <td><canvas id=\"customCanvas1\" width=\"400\" height=\"400\" /><br/>\n    <input type=\"range\" id=\"trackbar1\" value=\"50\" min=\"0\" max=\"100\" step=\"1\"/>\n    </td>\n\n    <td><canvas id=\"customCanvas2\" width=\"400\" height=\"400\" /><br/>\n    <input type=\"range\" id=\"trackbar2\" value=\"50\" min=\"0\" max=\"100\" step=\"1\"/>\n    </td>\n  </tr>\n\n  <tr>\n    <td><video id=\"customVideo1\" width=\"320\" height=\"240\" muted /></td>\n    <td><video id=\"customVideo2\" width=\"320\" height=\"240\" muted /></td>\n  </tr>\n</table>\n`)\n\n    const FPS = 30;\nlet processing = false\n  const canvas1 = document.getElementById('customCanvas1')! as HTMLCanvasElement\n  const canvas2 = document.getElementById('customCanvas2')! as HTMLCanvasElement\n  const video1 = document.getElementById('customVideo1')! as HTMLVideoElement\n  const video2 = document.getElementById('customVideo2')! as HTMLVideoElement\n  // const video = document.getElementById('videoInput')! as HTMLVideoElement\n// const  [processVideo, processVideo2]  = \n// Promise.all([video1.play(), video2.play()]).then(()=>{\n  // processing = true\n// })\n    // video1.src = url1\n    // video2.src = url2\n\ndebugger\n// const  [processVideo1, processVideo2] = [ await setupVideo(video1, canvas1, url1) , await setupVideo(video2, canvas2, url2)  ]\n// .then(()=>{\n//   processing = true\n// })\n\n// const  [start1, start2] = await Promise.all([setupVideo(video1, canvas1, url1),await setupVideo(video2, canvas2, url2) ])\n\nvar starts = await Promise.all([setupVideo(video1, canvas1, url1),await setupVideo(video2, canvas2, url2) ])\nstarts.forEach(start=>start())\n\n// start1\n// await Promise.all([processVideo1(), processVideo2()])\nawait new Promise(resolve => setTimeout(resolve, 120000))\n\n\n async  function setupVideo(video: HTMLVideoElement, canvas: HTMLCanvasElement, url: string) {\n    const src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\n    const dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\n    // const canvas = document.getElementById('outputCanvas')! as HTMLCanvasElement\n    const cap = new cv.VideoCapture(video);\n    const processVideo = () => {\n      try {\n        if (!processing) {\n          src.delete();\n          dst.delete();\n          return;\n        }\n        else {\n          const begin = Date.now();\n          cap.read(src);\n          cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);\n          cv.imshow(canvas, dst);\n          const delay = 1000 / FPS - (Date.now() - begin);\n          setTimeout(processVideo, delay);\n        }\n      }\n      catch (err) {\n        console.error(err);\n      }\n    };\n    //   // const processVideo = ;\n    // const v1 = new Mirada.CameraHelper(video, canvas, processVideo)\n    // setTimeout(v1.processVideo, 0)\n    // setTimeout(v1.stop, 6660)\n\n    video.src = url\n    await video.play()\n    // return () => setupVideo(video, canvas, url)\n    return  processVideo\n    // return  setupVideo(video, canvas, url)\n\n    // return processVideo;\n  }\n\n  // // const canvas = document.getElementById('outputCanvas')!\n  // // canvas.insertAdjacentHTML('afterend', `<input type=\"range\" id=\"trackbar\" value=\"50\" min=\"0\" max=\"100\" step=\"1\">`)\n  // var orange = await Mirada.fromUrl('orange.png')\n  // var apple = await Mirada.fromUrl('apple.png')\n  // let dst = new cv.Mat()\n  // let trackbar = document.getElementById('trackbar')! as HTMLInputElement\n  // const listener = () => {\n  //   let alpha = trackbar.valueAsNumber / parseInt(trackbar.max)\n  //   let beta = (1.0 - alpha)\n  //   cv.addWeighted(orange, alpha, apple, beta, 0.0, dst, -1)\n  //   cv.imshow(canvas, dst)\n  // }\n  // trackbar.addEventListener('input', listener)\n\n  // await sleep(600)\n  // listener()\n  // await sleep(12000)\n  // trackbar.removeEventListener('input', listener)\n  // document.getElementById('trackbar')!.remove()\n  // async function sleep(ms = 1000) { await new Promise(resolve => setTimeout(resolve, 1000)) }\n})()\n\n\n  // let cap1 = new cv.VideoCapture(video1)\n  // // take first frame of the video\n  // let frame1 = new cv.Mat(video1.height, video1.width, cv.CV_8UC4)\n  // cap1.read(frame1)\n  // let cap2 = new cv.VideoCapture(video2)\n  // let frame2 = new cv.Mat(video2.height, video2.width, cv.CV_8UC4)\n  // cap2.read(frame2)\n\n// function f (){} \n\n//   let video = document.getElementById('videoInput')! as HTMLVideoElement\n//   const canvas = document.getElementById('outputCanvas')! as HTMLCanvasElement\n//   let cap = new cv.VideoCapture(video)\n//   // take first frame of the video\n//   let frame1 = new cv.Mat(video.height, video.width, cv.CV_8UC4)\n//   cap.read(frame1)\n\n//   let prvs = new cv.Mat()\n//   cv.cvtColor(frame1, prvs, cv.COLOR_RGBA2GRAY)\n//   frame1.delete()\n//   let hsv = new cv.Mat()\n//   let hsv0 = new cv.Mat(video.height, video.width, cv.CV_8UC1)\n//   let hsv1 = new cv.Mat(video.height, video.width, cv.CV_8UC1, new cv.Scalar(255))\n//   let hsv2 = new cv.Mat(video.height, video.width, cv.CV_8UC1)\n//   let hsvVec = new cv.MatVector()\n//   hsvVec.push_back(hsv0); hsvVec.push_back(hsv1); hsvVec.push_back(hsv2)\n\n//   let frame2 = new cv.Mat(video.height, video.width, cv.CV_8UC4)\n//   let next = new cv.Mat(video.height, video.width, cv.CV_8UC1)\n//   let flow = new cv.Mat(video.height, video.width, cv.CV_32FC2)\n//   let flowVec = new cv.MatVector()\n//   let mag = new cv.Mat(video.height, video.width, cv.CV_32FC1)\n//   let ang = new cv.Mat(video.height, video.width, cv.CV_32FC1)\n//   let rgb = new cv.Mat(video.height, video.width, cv.CV_8UC3)\n\n//   const FPS = 30\n//   const videoHelper = new Mirada.CameraHelper(video, canvas, processVideo)\n//   function processVideo() {\n//     try {\n//       if (!videoHelper.streaming) {\n//         // clean and stop.\n//         prvs.delete(); hsv.delete(); hsv0.delete(); hsv1.delete(); hsv2.delete()\n//         hsvVec.delete(); frame2.delete(); flow.delete(); flowVec.delete(); next.delete()\n//         mag.delete(); ang.delete(); rgb.delete()\n//         return\n//       }\n//       let begin = Date.now()\n//       // processVideo processing.\n//       cap.read(frame2)\n//       cv.cvtColor(frame2, next, cv.COLOR_RGBA2GRAY)\n//       cv.calcOpticalFlowFarneback(prvs, next, flow, 0.5, 3, 15, 3, 5, 1.2, 0)\n//       cv.split(flow, flowVec)\n//       let u = flowVec.get(0)\n//       let v = flowVec.get(1)\n//       cv.cartToPolar(u, v, mag, ang)\n//       u.delete(); v.delete()\n//       ang.convertTo(hsv0, cv.CV_8UC1, 180 / Math.PI / 2)\n//       cv.normalize(mag, hsv2, 0, 255, cv.NORM_MINMAX, cv.CV_8UC1)\n//       cv.merge(hsvVec, hsv)\n//       cv.cvtColor(hsv, rgb, cv.COLOR_HSV2RGB)\n//       cv.imshow('outputCanvas', rgb)\n//       next.copyTo(prvs)\n//       // schedule the next one.\n//       let delay = 1000 / FPS - (Date.now() - begin)\n//       setTimeout(processVideo, delay)\n//     } catch (err) {\n//       console.error(err)\n//     }\n//   }\n//   setTimeout(() => videoHelper.processVideo(), 0)\n//   setTimeout(() => videoHelper.stop(), 10000)\n\n";
